The codeImport cv2import dlibimport matplotlib.pyplot as pltimport numpy as np# Paths to the pre-trained modelsFACE_DETECTION_MODEL = r'C:\Users\user\OneDrive\Desktop\python\mmod_human_face_detector.dat'GENDER_PREDICTION_MODEL = r'C:\Users\user\OneDrive\Desktop\python\gender_net.caffemodel'GENDER_PREDICTION_CONFIG = r'C:\Users\user\OneDrive\Desktop\python\gender_deploy.prototxt'AGE_MODEL_PATH = r'C:\Users\user\OneDrive\Desktop\python\age_net.caffemodel'AGE_MODEL_ CONFIG = r'C:\Users\user\OneDrive\Desktop\python\age_deploy.prototxt'# Load the face detection modelface_detector = dlib.cnn_face_detection_model_v1(FACE_DETECTION_MODEL)# Load the gender prediction modelgender_net = cv2.dnn.readNet(GENDER_PREDICTION_MODEL, GENDER_PREDICTION_CONFIG)# Load the age estimation modelage_model = cv2.dnn.readNetFromCaffe(AGE_MODEL_CONFIG, AGE_MODEL_PATH)# Image pathimage_path = r"C:\Users\user\OneDrive\Pictures\pp Alfons.jpg"def detect_faces(image_ path): # Load the input image image = cv2.imread(image_path) # Convert the image to grayscale gray = cv2.cvtColor(image, cv2. COLOR_BGR2GRAY) # Detect faces in the image faces = face_detector(gray, 1) # Extract face regions face_regions = [] for face in faces: x, y, w, h = face.rect.left(), face.rect.top(), face.rect.width(), face.rect.height() face_regions.append(gray[y:y+h, x:x+w]) return faces, face_regionsdef predict_gender(face_regions): predictions = [] for face in face_regions: # Convert grayscale image to 3-channel image face_rgb = cv2.cvtColor(face,  cv2. COLOR_GRAY2BGR) face_rgb = cv2.cvtColor(face_rgb, cv2. COLOR_BGR2RGB) # Preprocess the face region for gender prediction blob = cv2.dnn.blobFromImage(face_rgb, 1, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False) # Set the blob as input to the gender prediction model gender_net.setInput(blob) # Perform forward pass and get the gender predictions gender_preds = gender_net.forward() # Get the gender label gender_label = "Male" if gender_preds[0][0] > gender_preds[0][1] else "Female" # Append the gender label to the  predictions list predictions.append(gender_label) return predictions# Detect facesfaces, face_regions = detect_faces(image_path)# Predict gendergender_predictions = predict_gender(face_regions)# Load and preprocess the input imageimage = cv2.imread(image_path)image = cv2.resize(image, (224, 224))image = image.astype(np.float32) / 255.0# Perform age estimationage_model.setInput(cv2.dnn.blobFromImages([image], 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False) )age_preds = age_model.forward()# Extract predicted agespredicted_ages = age_preds[:, 0]# Load the imageimage = cv2.imread(image_path)# Display the output with bounding boxes, gender labels, and predicted agesfor face, gender, age in zip(faces, gender_predictions, predicted_ages): x, y, w, h = face.rect.left(), face.rect.top(), face.rect.width(), face.rect.height() cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255,  0), 2) cv2.putText(image, gender, (x, y - 10), cv2. FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) cv2.putText(image, f"Age: {int(age)}", (x, y - 40), cv2. FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)# Convert image from BGR to RGB for displaying with matplotlibimage_rgb = cv2.cvtColor(image, cv2. COLOR_BGR2RGB)# Display the image with gender predictions and agesplt.imshow(image_rgb)plt.axis('off')plt.show()
